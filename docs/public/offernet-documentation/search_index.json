[
["index.html", "Offer Network: concept and implementation Chapter 1 Introduction", " Offer Network: concept and implementation Kabir Veitas (kabir@singularitynet.io) 2018-07-25 Chapter 1 Introduction Offer Networks is a concept of an alternative economy where Agents (humans, AIs and or more/less simple programs and intelligences) find, negotiate and execute locally and globally beneficial series of not-only-monetary exchanges of goods (tangible and/or intangible). The singnet/offernet project is the continuation of prior research and brainstorming, well summarized by the workshop held at Vrije Universiteit Brussel in 2015. The initial motivation is to find conceptual and implementable ways for humans to express and share complex inter-subjective values of exchangeable items in fundamentally richer way than ‘flat’ &amp; ‘one-dimensional’ monetary economy warrants, while still leveraging advantages of it. Conceptually, one can generalize humans to any agents or processes, material / immaterial goods to any items (e.g. data) and by doing this come close to a general concept of ‘distributed marketplace of intelligences’ – which is SingularityNET is all about (only without strict emphasis on AI). The conceptual (and of course implementational) details of Offer Network are still very much in development (see list of resources to date in References) and both have to advance together with the SingularityNET concept and infrastructure in a ‘simulation modelling way’. The idea is that concept + development + simulations + experiments will co-inform each other and co-develop in the most efficient way. "],
["conceptual-framework.html", "Chapter 2 Conceptual framework 2.1 Open problems / features to consider 2.2 Conceptual Architecture 2.3 Performance measure", " Chapter 2 Conceptual framework 2.1 Open problems / features to consider Open problems and features are are conceptual and ‘implementation’ issues that the system has to address in one or another way or at least provide a potential to do that. There is not particular order to the listed items now and they will be updated as the work progresses. 2.1.1 Representation / theory of value In monetary exchange, the value of items is represented in a ‘flat’ and ‘one-dimensional’ way – in terms of money – which abstracts away subjective differences in how heterogenous agents value the same items of exchange. The main idea of Offer Networks is to allow for these subjective values to be (partially) externalized in a distributed marketplace in order to enable peer-to-peer exchanges. This should increase the total generation of value as compared to monetary markets which support consumerist dynamics. Yet the theory of value goes beyond purely Offer Networks concept and implementation. Usually theories of value try to posit some sort of globally accepted measure of value, existence of which alone facilitates the exchange of goods – giving rise for transactional role of money. Yet the notion of global measure of value automatically takes away the subjective values and local aspect of exchange – precisely the things that Offer Network is supposed to bring back. In any case, expression and communication of subjective values will involve some sort of simplification (in terms of map, vector representations or just behavioral preferences) which will need to be experimented with in a simulation model. 2.1.2 Description of items of exchange Whatever will be exchanged in the market will have to be somehow represented and stored in a system for subsequent search and discovery by other agents. This is obvious but not simple, taking into account that every agent may ‘want’ to express its subjective preferences regarding concrete item offered / demanded. Ways to represent items could be: Limited number of hard-coded types. Obviously simplest to implement (and, depending on the angle of simulation, could be practical for the start), yet less realistic for a full fledged Offer Networks system. Natural language descriptions (or at least structured natural language). This seems to be most realistic, but also hardest to implement, as would need some sort of NLP capabilities on behalf of agents. The advantage is that it would allow seamless interaction of humans with the system (see HMI). Vector representations. A sort of a middle ground between natural language and hard coded types; I am currently in favour of this one, since it allows to define a simple similarity measure between items within exchange – allowing also to map them with ‘fuzzy’ or ‘incomplete’ preferences – which is an essential and necessary feature of the system; Map representations. The problem with vector representations is that they will require a sort of global key map for the values in a vector. In a map representation, and agent could explicitly indicate keys and their values. The similarity calculation may become somewhat more complicated in this case. Sparse Distributed Representation (of HTM) (Ahmad and Hawkins 2015). Just an idea so far, but could be interesting to explore. 2.1.3 Similarity measure It should be possible to calculate similarity measures between items traded and their values (which is by the way not the same, taken into account emphasis on subjective values in Offer Networks…). This is where [representation / description of items of exchange] becomes important. The need of similarity measure also becomes important if taking into account incomplete preferences and selection for relevance of agents – they will somehow will need to find items that map to those incomplete preferences. 2.1.4 Matching algorithm and search Given a (potentially huge) set of agents with {demand, offer} pairs, where demands and offers are items represented in a chosen way (see representation of items), an atomic task of an Offer Network at any point of time would be to find the items demanded by some agents which are offered by other agents and swap them so that the value created for agents participating in an exchange increases. For the problematics related to the ‘total value’ see discussion on centralization / decentralization which is not directly related to the matching algorithm / search (except that matching algorithm itself is related to it…;). For the problematics of the very ‘search’ problem in Offer Network, see incomplete preferences / selection for relevance. Possible matching / search algorithms: Proposed in (B. Goertzel 2015a) by ben@singularitynet.io: Reducing the ON Matching problem to Weighted Boolean Optimization / MaxSAT;; Mapping ON Matching problem into OpenCog Atomspace and solving with the Open-WBO/MaxSAT solvers on it; Proposed, formalized and experimented with in (Goertzel 2017) by Zar Goertzel: Maximum Edge-Weight Matching (MAX-WEIGHT) Maximum 2-way Matching (MAX-2) Greedy Shortest Cycle (GSC) Dynamic Shortest Cycle (DYN-SC) Hanging ORpairs (HOR) Proposed in [unpublished] by kabir@singularitynet.io: Aggregation of distributed vertex-based computations on a graph (see Computational framework for details) 2.1.5 Incomplete preferences and selection for relevance In any close to realistic scenario agents cannot have complete and full preferences about everything what they demand / want (surely not if agents are humans) as well as an item of exchange cannot be represented completely and ‘non-ambiguously’. Furthermore, and more importantly conceptually, incomplete preferences of agents actually allow for communication, interaction, coordination and emergence rather than prevent it. Therefore allowing for incomplete preferences and foreseeing the mechanism of negotiation / individuation of incomplete (or in extreme cases – completely non-existent) preferences of interacting agents into behavioral choices is an essential aspect of a system aspiring for self-organizing dynamics. See The resolution of disparity in (Weinbaum (Weaver) and Veitas 2017) for a conceptual treatment of this aspect. The important implication for Offer Networks is that ‘matching’ of demands and offers or ‘finding’ chains of exchanges among several agents is actually not at all a search problem given the space of possibilities ({offer, demand} pairs) but rather the result of dynamic interaction / negotiation among agents, in which concrete preferences / behaviours (not present before interaction) emerge from incomplete preferences, disparities and partial (in)compatibilities. The former (search) is a special case of the latter (negotiation) and the system architecture should at least attempt / consider the general case / framework before delving into implementation of special cases – which are nonetheless important. The main centralization / decentralization issue is that in decentralized system there is no universal way to define relevance of items to all participants of the system (provide ‘best’ measures, ‘best’ reputation systems, etc.). Heterogeneous participants / agents will have different preferences and will select different aspects of the same item as important / unimportant to them – so will base decisions on a mechanism called selection for relevance. Consider also, that for any non-trivial agent the enacted preferences depend on the specific situation (e.g. Fido-dog agent built with OpenCog had a parameter ‘pee urgency’ which influenced its decisions…:)) as well as these preferences are incomplete in the first place. The implication is that preferences of agents can be identified and enacted only in the actual interaction of agents in the network and not prior to that. Anything beyond this (e.g. positing a global search mechanism / algorithm which chooses what is best for each agent based on their pre-announced preferences) is a movement towards centralization of a system – which may be needed or even desirable provided that limitations and advantages are wholly considered. 2.1.6 Human-machine interface The vision of Offer Networks as an alternative economy first and foremost is concerned about increasing the welfare of humans and enriching ‘their’ economies (B. Goertzel 2015b, 3). Therefore human participation should be considered in the design of the system, albeit most probably not in early experiments. Leaving aside technical issues of the interface this presents at least two more conceptual issues/challenges: 1) Representing human preferences is tricky. It is obviously related to the representation / theory of value and description of items of exchange issues as well as Incomplete preferences and selection for relevance. 2) Humans will not participate in the system that asks them to list more than a few of their preferences (even if they know them for sure which is often not the case) about demands and characteristics of offered items. The SingularityNET-type solution seems to be to populate an Offer Network with AI agents representing preferences of people and having ability to interact with them in order to learn those preferences – and that would be a basis for Human-Machine Interface (see Conceptual architecture further in this document). 2.1.7 Centralization / decentralization We use the following definition of decentralization: a system is decentralized if no agent has an ability to directly access the global state of the system. This does not prevent it to indirectly infer or collect the information about the system that allows to construct a representation of a global state (like Google does with Internet :); Likewise, a centralized system is where a single agent (or agents) have a privileged role to access a global state of the system, collect information about it and provide such ‘global unified view’ to the other agents in the system (almost like Google does with Internet :)); Google’s example fits to both definitions which is the result of ‘rich becomes richer’ network dynamics illustrating that an initially decentralized system (Internet) can become centralized by merely a self-organized process (preferential attachment network dynamics). It also illustrates that in reality there are no strict borders between centralized and decentralized systems – they form a continuum (see here for more. Suppose that a system initially consists of completely homogenous (in terms of knowledge/degree of connectivity and processing capacities) agents which are trying to find best ‘friends’ in the network. If these agents are autonomous, sooner or later some of them will turn out to be more successful so other agents will start finding ‘friends’ through them – they will become Facebooks and Googles of the SingularityNET – this dynamics is general for any self-organizing system of autonomous agents. Note, that without such mechanism, complexification, evolution and learning in and of a system is impossible. On the other hand, when a few agents become so powerful that they start to influence decisions of majority of other agents in the network, the availability of diversity of the network decreases – and that again prevents complexification, evolution and learning. Furthermore, self-organization and search is a resource hungry process, therefore we want some sort of mechanism which propagates successful strategies/knowledge that can be utilized by others. Furthermore #2, the preferred balance between centralization / decentralization (degree distribution in a network if you will) depends on specific challenges and environment that the system is being exposed to. E.g. in stable times it may be globally beneficial to have more centralization and utilize / share a few best patterns of behavior, yet during volatile times it may be instrumental for the overall survival / stability of the system to experiment more (so destroy centralized hierarchies / neglect the highest degree nodes, etc.). Bottom line is that an ideal system capable of evolving and learning should not be centralized or decentralized, but it has to dynamically find a way to combine two modes of operation and fluidly change their balance depending on circumstances. The conceptual problem is that internal ‘rich becomes richer’ dynamics is natural to decentralized systems / networks, yet the dissolution of centralized networks is not – it usually has to come from external sources with a threat to destroy the system… (see processes of integration and disintegration in (Veitas and Weinbaum 2015) for more). This discussion provides a few guiding principles for the architectural design: 1. It has to be flexible enough for implementing, testing and evaluating many different centralization / decentralization mechanisms and behaviors (in terms of Offer Network – matching algorithms, representations and other features mentioned in this section); 2. It has to allow for variety (at least in principle if not from day one) in the system so that to allow agents themselves to have a say about the preferred / best matching algorithm, reputation system, representation, etc. 3. The system has to be able to learn / spread new useful patterns and to forget old or not-useful ones fast. The ideal criteria for a successful system would be its fluidity in adapting (learning new and forgetting old) rather than optimality / efficiency with respect to a static situation (while it could be an aspect to consider too); The goal of the architectural design is to express / operationalize these principles in computational terms and build a simulation environment / framework to experiment with them – which is the topic of computational framework. Note also that from the computational standpoint, centralized algorithms are almost always more measurably efficient than decentralized for a simple (yet fundamental) reason that self-organization and resolution of disparities need additional resources (of time and memory). Finding clear cases, especially lending themselves to computer simulations with efficiency criteria that could give justice to Offer Networks distributed system is far from trivial and requires a rich simulation framework. 2.1.8 Memory / learning: emergence of identities A system that learns has necessary to have a memory in order to be able to remember (and forget) patterns. For a network of agents (including Offer Network and SingularityNET) such memory is a connectivity pattern among them. If a network of collaborating agents find an efficient way to pool their resources / competences and to solve complex type of problems together that cannot be solved individually it represents a new pattern. If this pattern becomes persistent, conceptually it can be viewed as a kind of ‘super-agent’ – so a new emerged identity in the network. For the conceptual treatment of the process see A descriptive model of the individuation of cognition (Weinbaum (Weaver) and Veitas 2017). In Computational framework part we try to see if a computational framework able to support this process and still be practically testable / usable can be conceived and implemented. 2.1.9 Storage of value / timed exchanges In the specific case of Offer Networks, memory (apart from persistent connectivity patterns) is the ability to store value by agents (represented in reputation / tokens, etc.) for the usage later in timed exchanges. This is an essential aspect of the system and has to be considered in the early design (if not in early implementations). 2.2 Conceptual Architecture Taken into account all Open problems / features to consider the proposed conceptual architecture of Offer Networks is summarized in the picture below. The goal of simulation modelling is to experiment and test more or less isolated aspects of this architecture taking into account the future need for eventual integration of the results into the complete framework. Figure 2.1: Conceptual architecture of OfferNet In this architecture, the Offer Network consists of humans, which are represented by one or more ON-AI agent, which learns the behavior/preferences of the represented human relevant to its role in an Offer Network. An ON-AI agent formulates and owns sets of rules of exchange == conditions of how items (owned by the human) are offered and demanded in the network. Items are represented in a way that allows to calculate their similarity and match most similar items (i.e if an item1 offered by agent1 is sufficiently similar to item2 demanded by agent2 then there is a high probability that it is a match and the exchange can be executed. In case the similarity is not perfect (in real scenarios this will be always the case), the differences and incomplete preferences have to be resolved via negotiation of respective ON-AI agents with or without human intervention if AI agents cannot solve the issue themselves – implying more complex information flows within the network than just passing commands of humans to AI agents and then network. We may also consider that humans that form the ‘outer’ layer of the network form a social network by knowing each other outside the Offer Network. This fact allows for distributed operation of the network without central authority – humans would join the network only via recommendations of friends. This social network could also be a basis for the distributed reputation system where reputation of an agent would depend on the reputation of its friends in Page Rank / Google Guice style. Of course the initial social network would be augmented by a social network between ON-AI agents on the basis of their operation already within Offer Network. The social network structure is important for distributed search of similar items, since (provided that the ‘small-world’ structure) every agent of the network can potentially reach every other agent in the network via small number of links1. The efficiency of the operation of the network depends not only on the ‘smartness’ of ON-AI agents, but also on the structure of the network. The conceptual model does not prevent for introduction of additional ‘governing’, ‘matching’ or ‘similarity search’ agents operating on the same data structure. 1: https://en.wikipedia.org/wiki/Small-world_network 2.3 Performance measure Measuring ‘performance’ of the network of heterogeneous agents each having subjective values and running different processes without resorting to some sort of over-simplistic average (like amount of money or reputation at the end of the simulation) is a tricky issue. Yet we need some kind of ways to distinguish successful simulations from unsuccessful ones. Possibilities are listed below: Proposed, formalized and experimented with in (Goertzel 2017) by Zar Goertzel: (TM): Total number of ORpairs satisfactorily matched. (WT): Average wait time of ORpairs that are matched. (AMS): Average number of matches accepted / suggested matches. (SMS): Average size of suggested matches.(PoD): Matched task popularity measured by average product of degrees (TH): Total number of ORpairs held. (HT): Average number of times a hanging ORpair is held. (HWT): Max wait time of a user in a held node Proposed and (to be) experimented with in [unpublished] by kabir@singularitynet.io: (Static performance): Time required by the network to find known-to-exist matches in the network which are pre-calculated in advance; (Learning rate): Time required by the network to find subsequently injected known-to-exist matches; 2.3.1 Information integration Conceptually the most interesting potential measure of performance of the network is information integration Φ, proposed by (Edelman and Tononi 2000). Φ formally defines coordinated clusters in networks of interacting agents across time and space and is used by (Tononi 2004) in developing an integrated theory of consciousness. Intuitively, “[a] subset of elements within a system will constitute an integrated process if, on a given time scale, these elements interact much more strongly among themselves than with the rest of the system” (Edelman and Tononi 2000, 135). Such measure could in principle allow to detect the emergence of ‘higher scale agents’ in the self-organizing network (see Memory / learning: emergence of identities) and goes far beyond Offer Networks as could be an overall measure of measuring intelligence – which would be fascinating to experiment with on Offer Networks in simplified manner (and SingularityNET for that matter). Measuring information integration of a dynamic network of heterogeneous agents adds another layer of complexity to the simulation, as the calculation of information integration may take considerable computational resources (potentially more than simulation itself…). While this is an interesting avenue to explore in the context of AGI research it is not currently considered in Computational framework. References "],
["computational-framework.html", "Chapter 3 Computational framework 3.1 Actor model of computation 3.2 Graph computing framework 3.3 Simulation engine 3.4 Notes", " Chapter 3 Computational framework The proposed Offer Networks simulation framework is based on (and is a special case of) the “open-ended computing” model, which combines two paradigms / computation models: Actor model of computation and Graph Computing Framework. 3.1 Actor model of computation A decentralized and distributed system from the computational perspective can be best described by Actor model (Agha 1986), which was introduced in 1973 as a “universal modular formalism for artificial intelligence” (Hewitt, Bishop, and Steiger 1973). The model defines interaction among independent processes via message passing that does not require a global observer / algorithm / manager. It aims to model intelligence “ […] in terms of a society of communicating knowledge-based problem-solving experts. In turn each of the experts can be viewed as a society that can be further decomposed in the same way until the primitive actors of the system are reached”. It models “the nature of the communication mechanisms needed for effective problem-solving by a society of experts and the conventions of discourse that make this possible” and is aimed for developing a framework for “problem-solving involving parallel versus serial processing and centralization versus decentralization of control and information storage” (Hewitt 1976). Over the years, actor model found its way into programming languages and paradigms, including, for example, functional programming. Also, there exists software frameworks and libraries dedicated to actor model (i.e. Akka, gpars, python/pulsar, etc.). These libraries allow for fast, yet scalable (across multiple machines) implementation of the actor model based logic. Actor model allows for operationalization of the ‘open-ended intelligence’ (Weinbaum (Weaver) and Veitas 2017), (Weinbaum (Weaver) 2018) concept which perceives intelligence as a formative process of self-organization in which agents themselves get formed – as opposed to seeing intelligent agents which competencies are defined with respect to an a priori given problem domain or goal. Open-ended intelligence concept emphasizes onto-genesis of intelligent agents (in terms of their cognitive development) rather than their specific properties. Considering requirements / open problems / features related to implementation of Offer Networks (see Offer Networks: conceptual framework), the operationalization of aspects of Open-ended intelligence concept with the Actor model for building simulation modelling experiments seems to be a sensible path towards a scalable infrastructure for alternative economy. Having said this one has to admit that Actor model (as well as the concept of Open-ended intelligence) is fairly abstract and does not define actual mechanisms of communications between actors and formation of their collectives able to solve complex tasks. The issue here is of course introducing the right set of constraints that will make the model more concrete without losing the essential characteristics which we would like to understand (see also the community discussion on the topic). For this a way to define logic of individual agent as well as communications between them is needed. 3.2 Graph computing framework Graph computing is both a set of technologies and a way of thinking about the world in terms of graph data structures – entities connected via explicit or implicit links – and the processes working on them in terms of graph traversals (Rodriguez 2013). Very large graph data structures can be stored and processed on multiple machine clusters using modern open source or commercial distributed graph database technologies (e.g. Janusgraph, Neo4J, Azure Cosmos DB, Amazon Neptune, Data Stax Enterprise Graph, etc.). Graph traversal is a process of visiting (checking, updating or modifying) vertices and links of a graph based on the user defined constraints (or grammar) (M. A. Rodriguez 2008) and is equivalent to ‘semantically constrained’ spreading activation, which can be regarded a general method of how associative networks (including brain) operate. Modern graph traversal engines (e.g. Apache TikerPop, currently used in the offernet) use vertex-centric programming model (also called “think like a vertex”), which implements user defined programs from the perspective of any vertex in a graph rather than the whole data structure (McCune, Weninger, and Madey 2015). This paradigm allows for implementation of decentralized model as well as other important features discussed in the Conceptual framework. Furthermore, both the paradigm and available technologies are massively scalable – allowing to process very large data structures without requiring to store/access them at once which (not incidentally) follows the conceptual approach to the world as a decentralized system – which cannot be properly modelled by assuming a global omniscient observer (see conceptual perspective of decentralized IT governance and (M. A. Rodriguez Marko 2008)). 3.3 Simulation engine The final goal of the offernet project is to build the simulation engine for simulating rich and large scale Offer Networks experiments considering the general architecture as well as particular solutions of SingularityNET network. The long term goal is to integrate/assimilate offernet into SingularityNET core architecture as well as use lessons learned. Ideally the simulation engine could be used for general SingularityNET simulations. The model of simulation engine consists of 4 layers (see figure 3.1). See also figure 2.1. Layer 4 is written in Java/Groovy/[Gremlin](https://en.wikipedia.org/wiki/Gremlin_(programming_language); layer 3 is Akka framework (Java); layer 2 is the DSE native graph API; and for layer 1 the Data Stax Enterprise Graph is currently used. Figure 3.1: Simulation framework layers Data Stax Enterprise Graph is a transactional database that can support thousands of concurrent connections and storing and querying graphs containing billions of vertices and edges, apart from being able to be distributed on multiple machines through Apache Cassandra (which is the backend of DSE graph) clusters. The network of items, rules of exchange and partially agents (see Conceptual framework and figure @ref{fig:architecture} are implemented as vertices and links in the graph. ON-AI agents access the graph and run distributed traversals using an Offer Network domain specific language written on Apache Tinkerpop’s Gremlin language’s (for now DSE java driver is chosen but could be other variant). ON-AI agents themselves will be implemented as sequential programs running on separate threads concurrently via Akka actors. In terms of scalability, Akka supports millions of actors and messages. Availability of concurrent connections is important for implementing actor model where actors will access the Offer Network graph asynchronously in order to simulate the dynamics of a realistic economic network composed of many heterogeneous actors in SingularityNET. Massive scalability of graph databases will allow for large scale experiments with simpler ON-AI agent logic (or not so simple, depending on the availability of computational resources). Furthermore, the model architecture would allow to run experiments with matching algorithms of (Goertzel 2017) on the same data structure and therefore potentially compare centralized search algorithms with decentralized search. The simulation engine / architecture briefly described above allows to run decentralized or centralized algorithms on the same data structure of the Offer Network whether statically constructed or dynamically changing – thus providing rich experimentation space for testing and comparing different ideas and algorithms. The best way to explain the model is in terms of data structures, objects and processes. See a semi-formal representation below. 3.3.1 Data structures and objects The structure is a list of vertexes and edges: \\[ON = \\left\\{ {V, E, \\lambda, \\mu} \\right\\}\\] where edges are directed (i.e. \\(E \\subset (V × V )\\)), edges are labelled (i.e. \\(\\lambda : E \\rightarrow \\Sigma\\)), and properties are a map from elements and keys to values (i.e. \\(\\mu : (V \\cup E) × R \\rightarrow S)\\) {Rodriguez and Neubauer (2010)}. Vertexes can be of type ‘agent’, ‘work’ or ‘item’: \\[\\begin{equation} \\begin{aligned} \\forall V ( &amp; type(V,\\text{agent})\\\\ &amp; \\lor type(V,\\text{work})\\\\ &amp; \\lor type(V,\\text{item})) \\end{aligned} \\end{equation}\\] Vertexes can be connected with edges, which define predicate relations between them: \\[\\begin{equation} \\begin{aligned} \\exists V1 \\exists V2 \\exists E &amp; (connected(V1,E,V2) \\\\ &amp; \\Leftrightarrow \\exists pred (pred(V1,V2) \\land type(E,\\text{pred}))) \\end{aligned} \\end{equation}\\] Edges can be of type ‘owns’, ‘offers’, ‘demands’ and ‘similar’ (which correspond to the possible predicate relations between vertexes): \\[\\begin{equation} \\begin{aligned} \\forall E ( &amp; type(E,\\text{owns}) \\\\ &amp; \\lor type(E,\\text{similar}) \\\\ &amp; \\lor type (E,\\text{offers}) \\\\ &amp; \\lor type (E,\\text{demands}) ) \\end{aligned} \\end{equation}\\] Agents ‘own’ works: \\[\\begin{equation} \\begin{aligned} owns(V1,V2) :\\Leftrightarrow &amp; \\forall V1 \\forall V2 \\forall E (type(V1,\\text{agent}) \\land type(V2,\\text{work}) \\\\ &amp; \\land connected(V1,E,V2) \\land type(E,\\text{owns}) ) \\end{aligned} \\end{equation}\\] A work ‘demands’ and/or ‘offers’ data: \\[\\begin{equation} \\begin{aligned} \\textit{demands}(V1,V2) :\\Leftrightarrow &amp; \\forall V1 \\forall V2 \\forall E (type(V1,\\text{work}) \\land type(V2,\\text{data}) \\\\ &amp; \\land connected(V1,E,V2) \\land type(E,\\text{demands})) \\end{aligned} \\end{equation}\\] \\[\\begin{equation} \\begin{aligned} \\textit{offers}(V1,V2) :\\Leftrightarrow &amp; \\forall V1 \\forall V2 \\forall E (type(V1,\\text{work}) \\land type(V2,\\text{data}) \\\\ &amp; \\land connected(V1,E,V2) \\land type(E,\\text{offers})) \\end{aligned} \\end{equation}\\] \\[\\begin{equation} \\begin{aligned} \\forall V1 (type(V1,\\text{work}) \\, \\exists V2 (demands(V1,V2) \\lor \\textit{offers}(V1,V2))) \\end{aligned} \\end{equation}\\] Another way to look at the same structure is that a ‘work’ is a ‘function’, taking inputs and converting them to outputs. In principle it can be a generic function as defined in mathematics, but in the context of offer networks the function does not do anything except exchanging input for the output. An agent, which ‘owns’ a ‘work’ could be understood as a sort of a ‘process’ which provides resources and intention behind exercising a function connected to it. Items can be connected with similarity relation: \\[\\begin{equation} \\begin{aligned} similar(V1,V2) :\\Leftrightarrow &amp; \\forall V1 \\forall V2 \\forall E (type(V1,\\text{data}) \\land type(V2,\\text{data}) \\\\ &amp; \\land connected(V1,E,V2) \\land type(E,\\text{similar})) \\end{aligned} \\end{equation}\\] \\[\\begin{equation} \\begin{aligned} \\forall E (type(E,\\text{similar}) \\Rightarrow \\exists! value(E,\\text{s})); s: \\rm I\\!R [0,1] \\end{aligned} \\end{equation}\\] 3.3.2 Processes (Gremlin DSL pseudo-code) Processes are graph traversals (written in Gremlin DSL) that run on separate threads of each agent. While the processes are concurrent and asynchronous, they nevertheless interact between each other by using the same data structure (OfferNet graph) in a stigmergic manner. Some of the processes are (full list will be available in the API documentation): findSimilar def findSimilar() { allOffersAndDemands.each {dataItem -&gt; dataItem.getProcess() .getAgent() .getNeighbours() .getProcesses() .getOffersAndDemands() .calculateSimilarity(dataItem) } }; findCycles def findCycles() { allAgents.each { agent -&gt; agent.getProcesses() .getOffersAndDemands() .getHighestSimilarityLink() .filter{link -&gt; link.similarity &gt; threshold} .remember(traversals) } if (traversals.contain(cycle) == true) { return cycle } }; 3.3.3 Expected dynamics (graphical depiction) Offer Network (toy) graph before running processes on it (i.e. similarities among items not calculated): After running processes and finding cycles: Similarity relation (based on Hamming distance): 3.4 Notes A graph database back-end is currently needed to enable the usage of graph traversal language for defining peer-to-peer communication rules among agents. In principle, however, it may be possible to implement Apache Tinkerpop OLTP graph computer directly on the chosen Actor framework (see Provider Documentation) or even on any code. In any case, implementing OLTP graph computer directly involves a considerable effort and therefore should be well backed by the results of initial experiments. References "],
["functional-description.html", "Chapter 4 Functional Description", " Chapter 4 Functional Description Functional description of the software is automatically generated from behavioural test suite (latest build report available is here). Every behaviour described below is already implemented and working. Note, therefore, that the aim of this section is to describe already implemented functionality, contrary to planned functionality, described elsewhere – e.g. Conceptual Framework. Therefore #2, the contents of this section gets augmented every time the new behaviour is implemented and tested – so evolves in parallel with the codebase. "],
["implementation.html", "Chapter 5 Implementation 5.1 Plans, goals &amp; phases 5.2 Simulation modelling 5.3 Implementation and Configuration Reference", " Chapter 5 Implementation 5.1 Plans, goals &amp; phases High level goals of the programme are described below. These goals are further (micro)managed via GitHub project management in singnet/offernet repository – see here or links related to each item. All issues/tasks are broken into 6 projects: Computational framework; Conceptual framework; Simulation modelling; Analysis engine; Documentation; Integration with SingularityNET prototype; 5.1.1 Goals (in no particular order) Medium-term: enable Offer Networks as an alternative to token-based exchange on SingularityNET…. Or rather, as a superclass of token-based exchange, since one type of offer that can be made is “to pay to X a certain number N of tokens of type T”; Implementation-wise / medium term: formulate offers and demands in a predicate-logic type format, compilable into executable smart contract form – issue; Continuous: Integration with SingularityNET prototype (Python, Solidity, Ethereum, etc.) – project; Short term: find an actual AI task to simulate for demonstration, communication purposes, conceptual coherence, etc – for boosting a fast prototyping process issue. Long-term: build an economic exchange network that would perform ‘better’ than purely monetary based exchanges (better in terms of global value created, customer satisfaction, etc.) – issue; Continuous: build and perform a fast prototyping / modelling / experimenting pipeline that feeds back to the conceptual development – project; Short-term: design the architecture which allows to combine – project: rich/expensive small-scale experiments, which let us explore and understand in-depth application implementation strategies, but aren’t actually more efficient than centralized approaches at the scale on which they’re being run; more simplistic scalable simulations, aimed at demonstrating/exploring the efficiency advantage achievable via decentralized methods at large scale 5.1.2 Phases (short-term): Exploratory work implementing Offer Networks atop SingularityNET and running preliminary experiments and simulations aimed at gaining knowledge and intuition. It may be beneficial to first construct experiments and simulations of isolated open problems / features to consider (search, memory, etc.) and get insights about them individually before integrating everything into one system. For this we may need to work out a more fine-grained schedule of goals / phases – milestones one and two. (medium-term): Get a concrete sense of what sorts of AI-related exchanges are going to have the property that Offer Network type exchange works better for them than token based exchange – issue; (long-term): Design and implement a scalable version of Offer Networks within SingularityNET, for handling an appropriate subset of AI interactions – project; 5.2 Simulation modelling The whole rationale of building the framework is to test conceptual ideas and hypotheses via simulation modelling. The way we are doing it roughly follows the following sequence: formulate a research question / hypothesis; design an experiment / simulation that could answer it; implement in software (which usually involves pushing the capabilities of the framework further); run, analyse, formulate &amp; publish results; go back to 1. and start all over again… This is again managed via GibHub – see the Simulation modelling project on singnet/offenet repo. Below are descriptions of already conceived experiments. Hopefully more will be added as we move forward, but we are not going to plan for more than 6-12 months into the future… 5.2.1 Compare decentralized and centralized search Github issue: #15; Due: milestone v0.1.0; The goal of Offer Networks could be operationalized as: search and execute globally optimal set of exchanges that would maximally satisfy outstanding offers/demands by maximum number of agents – see also (B. Goertzel 2015a). This goal can be achieved by centralized (global) or decentralized (local) search and matching of offer-demand pairs. Goal of this experiment is to compare these two modes and get insights about their relative advantages, disadvantages and trade-offs. 5.2.1.1 Definitions Centralized search is a search on the global state of the network. In other words, a process which is performing centralized search has full and perfect knowledge of all agents and their outstanding offers and demands. Such process then can pull all this information into a single data structure and calculate a set of exchanges that would optimize stated preferences of agents at the moment. Advantages: global optimality – the solution found is knowingly optimal; Disadvantage #1: depending on the size of the network may need a lot of memory in order to represent the whole network available for single process; Disadvantage #2: searching for optimal solution is computationally expensive and (may) lead to combinatorial explosion(s); Disadvantage #3 (derived from #2): exchange preferences (and preferences in general) have time value – agents in general would not be willing to wait for too long until their offers/demands are met; which means that globally optimal solution which cannot be reached fast enough may not be optimal at all… Decentralized search (or sometimes called ‘local’ search) is a search performed by an agent which does not have a privileged access /full information about the global state of the network and other agents. Decentralized process tries to pull as much locally available information as needed in order to achieve “good enough” satisfiability of individual preferences of an agent performing search /matching. Advantage #1: agents can potentially achieve better individual satisfaction of their preferences (since they do not need to calculate all possibilities leading to optimal solution); Advantage #2: the individual process is potentially faster (due to above); Disadvantage #1: global optimality is not guaranteed; Disadvantage #2: competition between agents without global arbiter may lead to inefficiencies; 5.2.1.2 Research question In what context (in terms of size of network, rate of change, connectivity of agents, etc.) decentralized search provides better results than centralized (and vice versa) in terms of number of matches found per unit of time. 5.2.1.3 Set-up Option #1: Benchmark centralized and decentralized algorithms on the same pre-constructed data structures of different sizes and complexities (offer network with known number of simple / complex matches); Calculate the trade-off between memory and time needed in both cases; Option #2: Set-up a dynamic network, where agents constantly add/withdraw offers and demands; benchmark centralized and decentralized algorithms on such network; In theory both options should be equivalent, but the second option is a more realistic (and somewhat more difficult to implement) simulation of the Offer Networks dynamics which potentially could lead to more insights. Anyway we start with the first option. 5.2.2 Design and demonstrate learning capabilities of the network Github issue: #17; Due: milestone v0.2.0; Preliminary research question: Building on Compare decentralized and centralized search experiment see if network learning / collaboration between agents would help decentralized search / matching approach globally optimal solution. 5.2.3 Complex barter transactions on top of monetary economy Github issue: #1; Due: December 31, 2018 (milestone v0.3.0); Design: TBD 5.3 Implementation and Configuration Reference Here we will document implementation decisions on the software level (including configuration) regarding Open problems / features to consider discussed in Conceptual framework. 5.3.1 Description of items of exchange (implementation) Jump to conceptual discussion of Description of items of exchange. As of now, items of exchange are represented as binary vectors of fixed length. The idea is each bit represents a feature of the item – 1 if item has this feature, 0 – if not. The length of vectors (i.e. number of features) can be set in the global configuration file. It seems that binary vectors are the best middle-way between fixed types and maps. We can easily simulate fixed types by defining a vocabulary and attributing binary string to every type – then set similarity threshold to 1, which means that the system will consider similar only vectors that are identical (if cosine similarity is used – see Similarity measure (implementation) below). 5.3.2 Similarity measure (implementation) Jump to conceptual discussion of Similarity measure. Currently there are two options for calculating similarity – modified hamming distance and cosine similarity. The latter is default, the former is easy to adopt, but is not included as configuration option as for now – some change of code (and tests) would be needed to switch between two: Modified Hamming distance (hidden) just calculates the number of how many bits in the same position are equal to 1 in both vectors. Which means that it calculates how many same features the two items have in common. See code of function: veitasSimilarity(CharSequence left, CharSequence right). The assumption here is that there is a global mapping of features (i.e. each position in a vector represents the same feature which are the same globally). This is a strong assumption which will probably not hold in anything close to real circumstances. That is the main reason why cosine similarity is default measure. Cosine similarity (default). The immediate advantage is that when similarity measure is calculated as cosine between vectors, it does not depend on the vector length – so decisions about similarity measure and representation of items are a bit more decoupled. Therefore, all kinds of system parameters, like similarityThreshold does not need to be adjusted when vector length changes (i.e. when items get explained by more features). See code of function: cosineSimilarity(String left, String right). It is also more forward looking to further advancement of the framework towards conceptual description. References "],
["references.html", "References", " References "]
]
